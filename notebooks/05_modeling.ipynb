{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path.cwd().parent / 'data'\n",
    "clean_data_path = DATA_DIR / 'processed' / 'ames_clean.pkl'\n",
    "with open(clean_data_path, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS.SubClass</th>\n",
       "      <th>MS.Zoning</th>\n",
       "      <th>Lot.Frontage</th>\n",
       "      <th>Lot.Area</th>\n",
       "      <th>Lot.Shape</th>\n",
       "      <th>Land.Contour</th>\n",
       "      <th>Lot.Config</th>\n",
       "      <th>Land.Slope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Bldg.Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Sale.Type</th>\n",
       "      <th>Sale.Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Condition</th>\n",
       "      <th>HasShed</th>\n",
       "      <th>HasAlley</th>\n",
       "      <th>Exterior</th>\n",
       "      <th>Garage.Age</th>\n",
       "      <th>Remod.Age</th>\n",
       "      <th>House.Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770.0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>...</td>\n",
       "      <td>GroupedWD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>5.332438</td>\n",
       "      <td>Norm</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622.0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>...</td>\n",
       "      <td>GroupedWD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>5.021189</td>\n",
       "      <td>Roads</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267.0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>...</td>\n",
       "      <td>GroupedWD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>5.235528</td>\n",
       "      <td>Norm</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160.0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>...</td>\n",
       "      <td>GroupedWD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>5.387390</td>\n",
       "      <td>Norm</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830.0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>...</td>\n",
       "      <td>GroupedWD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>5.278525</td>\n",
       "      <td>Norm</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MS.SubClass MS.Zoning  Lot.Frontage  Lot.Area Lot.Shape Land.Contour  \\\n",
       "0          20        RL         141.0   31770.0       IR1          Lvl   \n",
       "1          20        RH          80.0   11622.0       Reg          Lvl   \n",
       "2          20        RL          81.0   14267.0       IR1          Lvl   \n",
       "3          20        RL          93.0   11160.0       Reg          Lvl   \n",
       "4          60        RL          74.0   13830.0       IR1          Lvl   \n",
       "\n",
       "  Lot.Config Land.Slope Neighborhood Bldg.Type  ...  Sale.Type Sale.Condition  \\\n",
       "0     Corner        Gtl        NAmes      1Fam  ...  GroupedWD         Normal   \n",
       "1     Inside        Gtl        NAmes      1Fam  ...  GroupedWD         Normal   \n",
       "2     Corner        Gtl        NAmes      1Fam  ...  GroupedWD         Normal   \n",
       "3     Corner        Gtl        NAmes      1Fam  ...  GroupedWD         Normal   \n",
       "4     Inside        Gtl      Gilbert      1Fam  ...  GroupedWD         Normal   \n",
       "\n",
       "  SalePrice Condition HasShed  HasAlley Exterior Garage.Age Remod.Age  \\\n",
       "0  5.332438      Norm   False     False  BrkFace       50.0      50.0   \n",
       "1  5.021189     Roads   False     False  VinylSd       49.0      49.0   \n",
       "2  5.235528      Norm   False     False  Wd Sdng       52.0      52.0   \n",
       "3  5.387390      Norm   False     False  BrkFace       42.0      42.0   \n",
       "4  5.278525      Norm   False     False  VinylSd       13.0      12.0   \n",
       "\n",
       "  House.Age  \n",
       "0      50.0  \n",
       "1      49.0  \n",
       "2      52.0  \n",
       "3      42.0  \n",
       "4      13.0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('SalePrice', axis=1)\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model = pd.get_dummies(X, drop_first=True).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_model,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos (Treinamento e Hiperparâmetros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear Regressor model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Fit Model to the training data\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Crie uma função de scoring personalizada\n",
    "scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Perform 5-fold cross-validation on the linear model using negative MSE as the scoring metric.\n",
    "cv_scores = cross_val_score(linear_model, X_model, y, cv=5, scoring=scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Gradient Boosting Regressor model\n",
    "boosting_model = GradientBoostingRegressor()\n",
    "\n",
    "# Define a parameter grid for tuning the model\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],    # Number of boosting stages\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Step size shrinkage\n",
    "    'max_depth': [3, 5, 7],             # Maximum depth of each tree\n",
    "    'subsample': [0.8, 1.0],            # Fraction of samples used for fitting individual base learners\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the boosting model\n",
    "grid_search = GridSearchCV(estimator=boosting_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model and its parameters\n",
    "best_boosting_model = grid_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor Hiperparâmetros | Taxa de Aprendizagem | Profundidade Máx. | Número de etapas de reforço | Subsamples |\n",
    "--- | --- | --- | --- | --- |\n",
    " 1 | 0.1 | 3 | 300 | 0.8 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Best Hyperparameters: {'bootstrap': True, 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define a parameter grid for tuning the model\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [10, 20, 30, None],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],    # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False],       # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the Random Forest model\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model and its parameters\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "print(\"Best Hyperparameters:\", grid_search_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor Hiperparâmetros | Inicialização | Profundidade Máx. | Nº Mínimo Amostras Folha | Nº Mínimo Amostras | Número de árovres |\n",
    "--- | --- | --- | --- | --- | --- |\n",
    " 1 | True | 20 | 1 | 2 | 300 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.003164 | RMSE: 0.056247\n"
     ]
    }
   ],
   "source": [
    "mean_mse = -cv_scores.mean()\n",
    "rsme_ = np.sqrt(mean_mse)\n",
    "print(f\"MSE: {mean_mse:.6f} | RMSE: {rsme_:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 13.83%\n"
     ]
    }
   ],
   "source": [
    "errorlr = 100 * (10**rsme_ - 1)\n",
    "print(f'Average error: {errorlr:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.002784 | RMSE: 0.052766\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_boosting_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rsme_ = np.sqrt(mse)\n",
    "print(f\"MSE: {mse:.6f} | RMSE: {rsme_:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 12.92%\n"
     ]
    }
   ],
   "source": [
    "errorgb = 100 * (10**rsme_ - 1)\n",
    "print(f'Average error: {errorgb:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.003387 | RMSE: 0.058202\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rsme_ = np.sqrt(mse_rf)\n",
    "print(f\"MSE: {mse_rf:.6f} | RMSE: {rsme_:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 14.34%\n"
     ]
    }
   ],
   "source": [
    "errorrf = 100 * (10**rsme_ - 1)\n",
    "print(f'Average error: {errorrf:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a análise dos resultados obtidos com os três modelos de regressão avaliados, a escolha do Gradient Boosting Regressor se destacou como a mais adequada para o projeto devido ao seu desempenho superior em todas as métricas principais. A tabela comparativa mostra os seguintes valores de MSE (Mean Squared Error), RMSE (Root Mean Squared Error) e erro percentual para cada modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index | Modelo | MSE | RMSE | Error |\n",
    "--- | --- | --- | --- | --- |\n",
    " 1 | Linear Regression | 0.003144 | 0.056074 | 13.78% |\n",
    " 2 | Gradient Boosting Regressor | 0.002463 | 0.049625 | 12.11% |\n",
    " 3 | Random Forest Regressor | 0.003387 | 0.058202 | 14.34% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivo da Escolha do Gradient Boosting Regressor:\n",
    "\n",
    "- Menor MSE: O Gradient Boosting Regressor apresentou um MSE de 0.002463, o mais baixo entre os três modelos testados, indicando uma menor média dos erros ao quadrado, o que reflete uma maior precisão nas previsões;\n",
    "\n",
    "- Menor RMSE: O RMSE de 0.049625 do Gradient Boosting Regressor reforça seu bom desempenho, mostrando que o desvio entre os valores previstos e os valores reais foi o menor, comparado aos outros modelos;\n",
    "\n",
    "- Erro Percentual mais Baixo: Com um erro percentual de 12.11%, o Gradient Boosting Regressor foi o mais preciso, superando a Regressão Linear (13.78%) e o Random Forest Regressor (14.34%);\n",
    "\n",
    "- Equilíbrio entre Complexidade e Desempenho: Embora a Regressão Linear e o Random Forest Regressor apresentem resultados razoáveis, o Gradient Boosting Regressor se sobressai por combinar modelos simples de maneira otimizada, proporcionando previsões mais consistentes e um menor erro geral.\n",
    "\n",
    "Portanto, com base na análise dessas métricas, o Gradient Boosting Regressor foi selecionado como o modelo mais adequado para o projeto, equilibrando precisão e robustez de maneira superior aos outros modelos avaliados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impotância das Features e suas Implicações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features Mais Importantes:\n",
      "               importancia\n",
      "House.Age         0.267298\n",
      "Gr.Liv.Area       0.224913\n",
      "Total.Bsmt.SF     0.080920\n",
      "Garage.Cars       0.072054\n",
      "Exter.Qual_TA     0.047383\n",
      "Fireplaces        0.031416\n",
      "Remod.Age         0.030503\n",
      "BsmtFin.SF.1      0.025402\n",
      "X1st.Flr.SF       0.023915\n",
      "Central.Air_Y     0.018041\n"
     ]
    }
   ],
   "source": [
    "importancias = pd.DataFrame({'importancia': best_boosting_model.feature_importances_}, index=X_train.columns)\n",
    "\n",
    "importancias_ordenadas = importancias.sort_values('importancia', ascending=False)\n",
    "\n",
    "top_10_importantes = importancias_ordenadas.head(10)\n",
    "print(\"Top 10 Features Mais Importantes:\")\n",
    "print(top_10_importantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       50.0\n",
       "1       49.0\n",
       "2       52.0\n",
       "3       42.0\n",
       "4       12.0\n",
       "        ... \n",
       "2925    22.0\n",
       "2926    23.0\n",
       "2927    14.0\n",
       "2928    31.0\n",
       "2929    12.0\n",
       "Name: Remod.Age, Length: 2877, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Remod.Age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando as duas features com importância discrepante e suas possíveis implicações para a aplicação de negócios:\n",
    "\n",
    "- House.Age (Idade da Casa) - Importância: 0.264582<br>\n",
    "Implicação: A idade da casa tem uma grande influência no preço do imóvel. Casas mais novas tendem a ter um valor de mercado mais alto, já que provavelmente requerem menos manutenção e oferecem características mais modernas. Em um cenário de negócios, isso pode indicar que a empresa pode focar mais em propriedades novas ou reformadas, que podem ser mais atraentes para os compradores e gerar preços mais altos.\n",
    "\n",
    "- Gr.Liv.Area (Área útil da casa - em metros quadrados) - Importância: 0.220363<br>\n",
    "Implicação: A área útil da casa tem uma das maiores importâncias no preço, o que é intuitivo, já que casas maiores geralmente têm preços mais altos. Em termos de aplicação de negócios, isso sugere que oferecer imóveis maiores ou focar na maximização do espaço útil pode ser uma estratégia eficaz para aumentar o valor de mercado de uma propriedade. Além disso, pode influenciar as decisões de marketing e vendas, já que áreas maiores podem ser mais atraentes para famílias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consequências do desempenho do modelo final para a aplicação de negócios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As consequências para a aplicação de negócios sugerem que o foco deve estar em imóveis mais novos e recentemente reformados, pois a idade da casa e das reformas são variáveis importantes para determinar o valor de mercado. \n",
    "- Imóveis mais novos ou com reformas recentes tendem a ter um valor mais alto, e realizar melhorias em imóveis antigos pode aumentar significativamente seu preço de venda. \n",
    "- A maximização do espaço é crucial, já que a área útil da casa e a área do porão são grandes determinantes do preço, indicando que aumentar o tamanho da propriedade ou otimizar o uso de espaços, como converter porões, pode agregar valor. \n",
    "- As comodidades adicionais, como lareiras e vagas de garagem, também são muito valorizadas pelos compradores, o que implica que incorporar mais vagas ou lareiras pode ser uma boa estratégia de marketing para justificar preços mais altos. \n",
    "- A qualidade da construção, especialmente a aparência externa da casa, é um ponto de venda importante, e investir na melhoria do exterior pode aumentar significativamente o valor percebido do imóvel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma geral, as features mostram que o valor do imóvel em Ames, Iowa, é fortemente influenciado pela idade da casa, pelo espaço útil, pelas comodidades (como garagem e lareiras) e pela qualidade da construção. Isso oferece orientações valiosas para ajustar a oferta de imóveis e as estratégias de marketing, além de fornecer insights sobre como otimizar o preço das propriedades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação do Modelo para Produção\n",
    "O modelo final de Gradient Boosting Regressor foi treinado e validado com sucesso, apresentando um desempenho superior em relação aos outros modelos avaliados. Para preparar o modelo para produção nós os retrainamos com as features mais importantes e os hiperparâmetros otimizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Feature Indices: [154   7   3  33  18 118  19   6  10  34]\n",
      "      Central.Air_Y  X1st.Flr.SF  BsmtFin.SF.1  Remod.Age  Fireplaces  \\\n",
      "1446           True       1174.0         781.0       30.0         0.0   \n",
      "981            True       1091.0         114.0       13.0         0.0   \n",
      "1703           True       1143.0           0.0        2.0         1.0   \n",
      "2699           True       1921.0           0.0       42.0         0.0   \n",
      "1343          False        808.0           0.0       13.0         0.0   \n",
      "\n",
      "      Exter.Qual_TA  Garage.Cars  Total.Bsmt.SF  Gr.Liv.Area  House.Age  \n",
      "1446           True          2.0          864.0       1174.0       30.0  \n",
      "981            True          1.0          384.0       1091.0       16.0  \n",
      "1703          False          3.0         1143.0       2473.0        3.0  \n",
      "2699           True          2.0         1921.0       1921.0       42.0  \n",
      "1343           True          1.0            0.0        808.0       63.0  \n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Retrieve feature importances from the best boosting model\n",
    "feature_importances = best_boosting_model.feature_importances_\n",
    "\n",
    "# Get indices of the top 10 most important features\n",
    "top_10_indices = np.argsort(feature_importances)[-10:]  # Get the indices of the 10 highest values\n",
    "\n",
    "# Print the feature importances for reference\n",
    "print(\"Top 10 Feature Indices:\", top_10_indices)\n",
    "\n",
    "# Filter the training and testing data to include only the top 10 features\n",
    "X_train_top_10 = X_train.iloc[:, top_10_indices]\n",
    "X_test_top_10 = X_test.iloc[:, top_10_indices]\n",
    "\n",
    "print(X_train_top_10.head())\n",
    "\n",
    "grid_search = GridSearchCV(estimator=boosting_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train_top_10, y_train)\n",
    "best_boosting_model_reduced = grid_search.best_estimator_\n",
    "with open('C:/Insper_real_oficial/machine_learning/projeto_ames/model/model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_boosting_model_reduced, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
